import { BayesClassifier, WordTokenizer } from 'natural';

interface DatasetSample {
    code: string;
    label: number;
}

// Example dataset (Replace this with your actual dataset)
const dataset: DatasetSample[] = [{
    'code': `const users = [
    { username: 'admin', password: 'admin123', role: 'admin' },
    { username: 'user', password: 'user123', role: 'user' }
  ];
  
  app.use(bodyParser.json());
  
  app.post('/login', (req, res) => {
    const { username, password } = req.body;
    const user = users.find(u => u.username === username && u.password === password);
`, 'label': 1
}]

// removing repeated data
function removeRedundantData(dataset: DatasetSample[]): DatasetSample[] {
    const uniqueEntries: DatasetSample[] = [];
    const seenEntries: Set<string> = new Set();
    let count0: number = 0;
    let count1: number = 0;
    for (const entry of dataset) {
        const entryString = JSON.stringify(entry);
        if (!seenEntries.has(entryString)) {
            if (entry.label === 0) count0++;
            else count1++;
            uniqueEntries.push(entry);
            seenEntries.add(entryString);
        }
    }
    // console.log(count0, count1, uniqueEntries.length);
    return uniqueEntries;
}

// Function to detect vulnerability brute force attack in a new code snippet
export function insecureAuthentication(code_snippet: string): void {
    let detect: boolean = false;
    // Create a tokenizer
    const tokenizer = new WordTokenizer();
    // Vectorize the new code snippet
    const tokenizedSnippet = tokenizer.tokenize(code_snippet);
    // Make prediction using the trained classifier
    if (tokenizedSnippet !== null) {
        // Prepare the data for training
        const cleanedDataset = removeRedundantData(dataset);
        const code_samples: string[] = cleanedDataset.map((sample) => sample.code);
        const labels: number[] = cleanedDataset.map((sample) => sample.label);
        // Vectorize the code samples using the tokenizer
        const tokenizedSamples: string[][] = code_samples
            .map((code) => tokenizer.tokenize(code))
            .filter((tokens) => tokens !== null) as string[][];
        // Train a Naive Bayes classifier
        const classifier = new BayesClassifier();
        for (let i = 0; i < tokenizedSamples.length; i++) {
            classifier.addDocument(tokenizedSamples[i], labels[i].toString());
        }
        classifier.train();
        const prediction = classifier.classify(tokenizedSnippet);
        const result = parseInt(prediction);
        if (result) {
            detect = true;
            const result: string = "==> Code vulnerable to Brute force Attack in this file!!! ";
            console.log(result.red);
        }
    }
    if (!detect) {
        console.log("==> Code NOT vulnerable to Brute force Attack".green);
    }
}