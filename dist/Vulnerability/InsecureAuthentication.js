"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.insecureAuthentication = void 0;
const natural_1 = require("natural");
// Example dataset (Replace this with your actual dataset)
const dataset = [{
        'code': `const users = [
    { username: 'admin', password: 'admin123', role: 'admin' },
    { username: 'user', password: 'user123', role: 'user' }
  ];
  
  app.use(bodyParser.json());
  
  app.post('/login', (req, res) => {
    const { username, password } = req.body;
    const user = users.find(u => u.username === username && u.password === password);
`, 'label': 1
    }];
// removing repeated data
function removeRedundantData(dataset) {
    const uniqueEntries = [];
    const seenEntries = new Set();
    let count0 = 0;
    let count1 = 0;
    for (const entry of dataset) {
        const entryString = JSON.stringify(entry);
        if (!seenEntries.has(entryString)) {
            if (entry.label === 0)
                count0++;
            else
                count1++;
            uniqueEntries.push(entry);
            seenEntries.add(entryString);
        }
    }
    // console.log(count0, count1, uniqueEntries.length);
    return uniqueEntries;
}
// Function to detect vulnerability brute force attack in a new code snippet
function insecureAuthentication(code_snippet) {
    let detect = false;
    // Create a tokenizer
    const tokenizer = new natural_1.WordTokenizer();
    // Vectorize the new code snippet
    const tokenizedSnippet = tokenizer.tokenize(code_snippet);
    // Make prediction using the trained classifier
    if (tokenizedSnippet !== null) {
        // Prepare the data for training
        const cleanedDataset = removeRedundantData(dataset);
        const code_samples = cleanedDataset.map((sample) => sample.code);
        const labels = cleanedDataset.map((sample) => sample.label);
        // Vectorize the code samples using the tokenizer
        const tokenizedSamples = code_samples
            .map((code) => tokenizer.tokenize(code))
            .filter((tokens) => tokens !== null);
        // Train a Naive Bayes classifier
        const classifier = new natural_1.BayesClassifier();
        for (let i = 0; i < tokenizedSamples.length; i++) {
            classifier.addDocument(tokenizedSamples[i], labels[i].toString());
        }
        classifier.train();
        const prediction = classifier.classify(tokenizedSnippet);
        const result = parseInt(prediction);
        if (result) {
            detect = true;
            const result = "==> Code vulnerable to Brute force Attack in this file!!! ";
            console.log(result.red);
        }
    }
    if (!detect) {
        console.log("==> Code NOT vulnerable to Brute force Attack".green);
    }
}
exports.insecureAuthentication = insecureAuthentication;
