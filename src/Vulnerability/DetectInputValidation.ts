import { BayesClassifier, WordTokenizer } from 'natural';
import path from 'path';
import { parsingCSVData } from '../parsingCSVData';

interface DatasetSample {
    code: string;
    label: number;
}

// removing repeated data
function removeRedundantData(dataset: DatasetSample[]): DatasetSample[] {
    const uniqueEntries: DatasetSample[] = [];
    const seenEntries: Set<string> = new Set();
    let count0: number = 0;
    let count1: number = 0;
    for (const entry of dataset) {
        const entryString = JSON.stringify(entry);
        if (!seenEntries.has(entryString)) {
            if (entry.label === 0) count0++;
            else count1++;
            uniqueEntries.push(entry);
            seenEntries.add(entryString);
        }
    }
    // console.log(count0, count1, uniqueEntries.length);
    return uniqueEntries;
}

// Function to detect vulnerability brute force attack in a new code snippet
export async function detectInputValidation(code_snippet: string): Promise<void> {
    try {
        let detect: boolean = false;
        // Create a tokenizer
        const tokenizer = new WordTokenizer();

        // Vectorize the new code snippet
        const tokenizedSnippet = tokenizer.tokenize(code_snippet);

        // Parsing dataset from CSV   
        const csvPath = path.join(__dirname, "../datasets", "inputValidationDataset.csv");
            
        const dataset = await parsingCSVData(csvPath);

        // Make prediction using the trained classifier
        if (tokenizedSnippet !== null) {

            // Prepare the data for training
            const cleanedDataset = removeRedundantData(dataset);
            const code_samples: string[] = cleanedDataset.map((sample) => sample.code);
            const labels: number[] = cleanedDataset.map((sample) => sample.label);

            // Vectorize the code samples using the tokenizer
            const tokenizedSamples: string[][] = code_samples
                .map((code) => tokenizer.tokenize(code))
                .filter((tokens) => tokens !== null) as string[][];

            // Train a Naive Bayes classifier
            const classifier = new BayesClassifier();
            for (let i = 0; i < tokenizedSamples.length; i++) {
                // console.log("hi")
                classifier.addDocument(tokenizedSamples[i], labels[i].toString());
            }
            classifier.train();
            const prediction = classifier.classify(tokenizedSnippet);
            const result = parseInt(prediction);
            if (result) {
                detect = true;
                const result: string = "==> Code having improper input validation, vulnerable to DOS Attack:!!! ";
                console.log(result.red);
            }
        }
        if (!detect) {
            console.log("==> Code having proper input validation".green);
        }
    } catch (error) {
        console.log(error);
    }

}
